{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f7b6bb42013a5637481957308d5a7306471b0750c3dc1fade55b6a2f7e8aac12"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Pclass     Sex  SibSp     Fare Embarked\n",
       "0       3    male      1   7.2500        S\n",
       "1       1  female      1  71.2833        C\n",
       "2       3  female      0   7.9250        S\n",
       "3       1  female      1  53.1000        S\n",
       "4       3    male      0   8.0500        S"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>SibSp</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>male</td>\n      <td>1</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>female</td>\n      <td>1</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>female</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>female</td>\n      <td>1</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv ('train.csv')\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "allColumns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Survived']\n",
    "data = data [allColumns]\n",
    "data.dropna ()\n",
    "X = data [features]\n",
    "y = data ['Survived']\n",
    "X.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.0 1.0 'male' 1 7.25 'S']\n [0.0 0.0 'female' 1 71.2833 'C']\n [0.0 1.0 'female' 0 7.925 'S']\n [0.0 0.0 'female' 1 53.1 'S']\n [0.0 1.0 'male' 0 8.05 'S']]\n[[1.0 0.0 1.0 1 7.25 'S']\n [0.0 0.0 0.0 1 71.2833 'C']\n [0.0 0.0 1.0 0 7.925 'S']\n [0.0 0.0 0.0 1 53.1 'S']\n [1.0 0.0 1.0 0 8.05 'S']]\n[[0.0 1.0 0.0 1.0 0.0 1.0 1 7.25]\n [0.0 0.0 0.0 0.0 0.0 0.0 1 71.2833]\n [0.0 1.0 0.0 0.0 0.0 1.0 0 7.925]\n [0.0 1.0 0.0 0.0 0.0 0.0 1 53.1]\n [0.0 1.0 0.0 1.0 0.0 1.0 0 8.05]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct1 = ColumnTransformer ([('one_hot_encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array (ct1.fit_transform (X))\n",
    "X = X [:, 1:]\n",
    "print (X[:5])\n",
    "\n",
    "ct2 = ColumnTransformer ([('one_hot_encoder', OneHotEncoder(), [2])], remainder='passthrough')\n",
    "X = np.array (ct2.fit_transform (X))\n",
    "X = X[:, 1:]\n",
    "print (X[:5])\n",
    "\n",
    "ct3 = ColumnTransformer ([('one_hot_encoder', OneHotEncoder(), [5])], remainder='passthrough')\n",
    "X = np.array (ct3.fit_transform (X))\n",
    "X = X[:, 1:]\n",
    "print (X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-0.30756234  0.61930636 -0.0474312   0.73769513 -0.51015154  0.90258736\n   0.43279337 -0.50244517]\n [-0.30756234 -1.61470971 -0.0474312  -1.35557354 -0.51015154 -1.10792599\n   0.43279337  0.78684529]\n [-0.30756234  0.61930636 -0.0474312  -1.35557354 -0.51015154  0.90258736\n  -0.4745452  -0.48885426]\n [-0.30756234  0.61930636 -0.0474312  -1.35557354 -0.51015154 -1.10792599\n   0.43279337  0.42073024]\n [-0.30756234  0.61930636 -0.0474312   0.73769513 -0.51015154  0.90258736\n  -0.4745452  -0.48633742]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_X.fit (X)\n",
    "X = sc_X.transform(X)\n",
    "print (X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7808988764044944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "model = RandomForestClassifier (n_estimators = 500)\n",
    "\n",
    "model.fit (X_train, y_train)\n",
    "\n",
    "y_pred = model.predict (X_test)\n",
    "\n",
    "correctAnswers = 0\n",
    "for i in range (len (y_pred)):\n",
    "    if y_pred [i] == y_test [y_test.index [i]]:\n",
    "        correctAnswers += 1\n",
    "\n",
    "print (correctAnswers/i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}